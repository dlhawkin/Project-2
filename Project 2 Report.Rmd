---
title: "Project2 Report"
author: "Diahmin Hawkins dlh2166@columbia.edu"
date: "11/6/2024"
output:
  pdf_document: default
  html_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE,
                      message = FALSE,
                      echo = FALSE,
                      fig.align = "center")
```




```{r}
library(readr)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(MASS)
library(tidyr)
library(kableExtra)
library(knitr)
library(GGally)
library(naniar)
library(visdat)
library(gtsummary)
library(gt)
library(mice)
library(corrplot) 
library(reshape2)
library(ggwordcloud)
library(magick)
library(glmnet)
library(caret)
library(car)
library(broom)

```

```{r, eval=FALSE}



# Path to your image
fig_path2 <- "/Users/diahminhawkins/Documents/GitHub/Project2/SmokePicture.png"

# Load the image using magick
img2<- image_read(fig_path2)

# Convert image to raster for use in ggplot
img_raster2<- as.raster(img2)


# Example data
words <- c("Smoking Cessation", "Depression", "MDD", "Readiness", "FTCD", 
           "Menthol", "Antidepressant", "Gender", "Carbon Monoxide", "BDI", 
           "Duration", "Waking up Smoking", "Psychiatric Diagnosis", "Black", "Hispanic","Non-white Hispanic", 
         "Anhedonia","Complimentary Reinforcers", "Substitute Reinforcers",
         "Cigarette Reward", "Varenicline", "Behavioral Activations", "Pharmacotherapy","Psychotherapy")

frequencies <- c(1, 18, 1, 16, 14, 55, 5, 1, 4, 42, 3, 14, 14, 18, 16, 4,7,9,10,22, 55, 36, 40,55)

new_frame <- data.frame(words, frequencies)

# Generate the word cloud on top of the image background
ggplot(new_frame, aes(label = words, size = frequencies)) +
  # Add the image background
  annotation_raster(img_raster2, xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf) +
  
  # Generate the word cloud
  geom_text_wordcloud(aes(color = frequencies)) +
  scale_size_area(max_size = 10) +
  
  # Customize the colors of the words
  scale_color_gradient(low = "white", high = "black") +
  
  # Remove axis titles and labels since we want the word cloud only
  theme_void()


```


# Introduction 

Mental health disorders are among the most common health conditions associated with tobacco dependence. Studies have shown that smokers with depression find smoking more pleasurable and are more dependent on nicotine, leading to more severe withdrawal symptoms than smokers without major depressive disorder (MDD). Dr. George Papandonatos, from Brown University’s highly regarded Biostatistics Department (ranked #14 in the country by U.S. News & World Report’s Best Graduate Schools), has investigated smoking cessation outcomes in adults diagnosed with MDD.


This study was conducted in research clinics at Northwestern University (Chicago, IL) and the University of Pennsylvania (Philadelphia, PA). Findings from this research indicate that individuals with MDD tend to smoke more heavily, exhibit greater nicotine dependence, and endure more severe withdrawal symptoms than individuals without MDD. According to `Efficacy and Safety of Combination Behavioral Activation for Smoking Cessation and Varenicline for Treating Tobacco Dependence among Individuals with Current or Past Major Depressive Disorder: A 2 × 2 Factorial, Randomized, Placebo-Controlled Trial`, "In conclusion, we found strong evidence that varenicline improved both short- and long-term abstinence rates relative to placebo among racially and socio-economically diverse adults with varied motivation to quit and varied psychiatric presentations" (Hitsman, Papandonatos, et al., 1722). While varenicline has proven effective in supporting smoking cessation, addressing the psychological aspects of smoking behavior, particularly those linked to depression, may further enhance cessation rates among adults with MDD.


The prior study employed a randomized, placebo-controlled, 2x2 factorial design to compare behavioral activation for smoking cessation (BASC) against standard behavioral treatment (ST), with an additional comparison of varenicline versus placebo. This study included 300 adult smokers with either current or past MDD. Findings indicated that BASC did not surpass standard behavioral treatment in effectiveness, regardless of concurrent varenicline therapy.

This current study will focus on three primary aims. The first aim is to assess baseline characteristics as potential moderators of the effects of behavioral treatment on end-of-treatment (EOT) abstinence. The second aim is to investigate whether baseline predictors of abstinence vary depending on the type of behavioral intervention and pharmacotherapy administered. The third aim is to identify which baseline variables (e.g., demographic, psychological, and clinical factors) have the strongest influence on abstinence outcomes. We hypothesize that certain baseline characteristics will significantly interact with treatment type, influencing the likelihood of smoking cessation. interact with treatment type, influencing the likelihood of smoking cessation.



```{r}
#Load the data in
project2<- read_csv("project2.csv")


#Check for missing data
#project2%>% vis_dat()
#vis_miss(project2)
#project2%>% glimpse()
```
# Methods
The raw data used for this analysis consisted of 300 rows and 25 columns. To begin this analysis, I got the sum of missing values from the dataset by columns. From this analysis, it was observed that the variables `Income`, `FTCD Score at Baseline`, `Cigarette Reward Value at  Baseline`, `Anhedonia`, `Nicotine Metabolism Ratio`, `Exclusive Mentholated Cigarette User`, and`Baseline Readiness to Quit Smoking` contained missing data. The missing data were examined using the `naniar` package in R to determine the percentage missing and available in the data. Following this procedure, there is a percentage of 21.67% of missing data.The missing percentage goes as follows: Income(1%), FTCD Score at Baseline (.33%), Cigarette Reward Value at  Baseline (6%), Anhedonia (1%), Nicotine Metabolism Ratio (7%), Exclusive Mentholated Cigarette User(.67%), and Baseline Readiness to Quit Smoking (5.67%). To further quantify the extent of missingness, the `naniar package` in R was employed to calculate the percentage of missing and available data.The missing data represent only .9% of the dataset, while 99.1% of the data remains well-represented. Therefore,these missing data properties led to the implementation imputation.


## Multiple Imputations
`Multiple Imputation` is a statistical process in the `mice` package that handles missing data by creating several datasets that fills in missing values.In the case here, we will imputate 5 different datasets for more accurate analyses by accounting for the uncertainty around the missing data, compared to single imputation methods that replace missing values with a single estimate.Each imputed dataset is then analyzed independently using the same statistical model, treating each as if it were the real, complete data. The statistical model we will be anticipating throughout this process is `Logistic`, `Lasso Regressions` and `Best Subset` regression. Following these results, we will pool the results by averageing them across the column using Rubin's Rules.

## EDA (Exploratory Data Analysis)
To explore the relationships of the categorical variables, a `Chi-Squared` test is used to determine whether there is a significant association . Through this process, it compares the observed frequencies in different categories with the expected frequencies to see if any differences are likely due to chance.This test assesses whether two categorical variables are independent of each other, identify patterns, relationships, and potential associations of the risk factors and the outcome of abstinence.

After exploring the categorical relationship, we will observe  the correlations of all the variables. Based on this plot, we we will observe potential risk factors to explore in our logistic model.

## Logistic
The logistic regression model doesn't use a penalty term and it's objective is to model the probability of a binary outcome Pr(Y=1|X) OR Pr(Y=0|X). Logistic regression uses the MLE (Maximum Likelihood Estimate) of the observed data without imposing any regularization on the coefficients. Logistic regression finds the coefficients that best predict the outcome based on the given predictors by maximizing the likelihood (or minimizing the negative log-likelihood). After finding the statistical significance using $\alpha<=05$, we will observe the variable of importance of our best model.


## Lasso
In the lasso regression model, we use the $l_1$ penalty rather than the $l_2$, where we take the absolute value of the $\beta$ rather than the squaring them. The $l_1$ penalty has the effect of forcing some of the coefficients to be exactly equal to zero. Lasso performs variable selection and models are easier to interpret that produces sparse models due to all the zeroes represented inside of the model.After observing our $\beta$ coefficients, we observe the non-zero coeffiecients in both our main effects model and interaction term model.The non-zero coefficients represent the predictor variables that have the most impact on our model and on the prediction of abstinence. 

# Comparison Analysis (Area Under the Curve (AUC))
Following the regression model analysis, we will evaluate and compare the performance of the logistic and LASSO regression models. This comparison aims to assess each model’s predictive accuracy, interpretability, and ability to identify significant predictors of abstinence.We will compare the models based on performance metrics AUC (Area Under the Curve) both training and testing datasets. These metrics will help evaluate how well each model generalizes to unseen data and its ability to distinguish between abstinent and non-abstinent outcomes.The Area Under the Curve (AUC) is a metric used to evaluate the performance of binary classification models. Specifically, it refers to the area under the Receiver Operating Characteristic (ROC) Curve, which plots the True Positive Rate (Sensitivity) against the False Positive Rate (1 - Specificity) at various threshold levels. The AUC provides an aggregate measure of a model's ability to distinguish between positive and negative classes across all possible classification thresholds. An AUC value of 1 indicates a perfect model that can correctly classify all cases, while an AUC of 0.5 suggests the model performs no better than random guessing. Higher AUC values reflect stronger model performance and greater discriminatory power. AUC is particularly useful because it is independent of any specific threshold, offering a more comprehensive understanding of the model's effectiveness in distinguishing between classes.

```{r} 
#Get all the missing data from each column
Missing_Data<- sapply(project2, function(x) sum(is.na(x)))
# Convert to dataframe
Missing_Data_df <- data.frame(ColumnName = names(Missing_Data), `Missing Data` = Missing_Data)

# Set names for the dataframe columns if necessary
names(Missing_Data_df) <- c("Variables", "Missing Data")

# Calculate the total number of rows in the dataset
total_rows <- nrow(project2)  


#Create Missing Data Summary
missing_data_summary <-Missing_Data_df %>%  
  filter(Variables %in% c('ftcd_score', 'inc', 'crv_total_pq1', 'shaps_score_pq1', 
                          'NMR', 'Only.Menthol', 'readiness')) %>%
    mutate(Percent_Missing = (`Missing Data` / total_rows) * 100) %>%
  dplyr::select(Variables, `Missing Data`, Percent_Missing)%>%
  mutate(Variables = case_when(
   Variables == "ftcd_score" ~ "FTCD Score at Baseline",
     Variables == "inc" ~ "Income",
    Variables == "crv_total_pq1" ~ "Cigarette Reward Value at  Baseline",
   Variables == "shaps_score_pq1" ~ "Anhedonia",
    Variables == "NMR" ~ "Nicotine Metabolism Ratio",
    Variables == "Only.Menthol" ~ "Exclusive Mentholated Cigarette User",
    Variables == "readiness" ~ "Baseline Readiness to Quit Smoking"))

# Obtain the total missing data and the percentage or missing data
total_missing <- sum(missing_data_summary$`Missing Data`)
percent_missing_total <- (total_missing / total_rows) * 100

#Create row to combine with the summart table
total_row <- data.frame(
  Variables = "Total",
  `Missing Data` = total_missing,
  Percent_Missing =percent_missing_total
)

#Both data frames have identical column names 
names(total_row) <- names(missing_data_summary)

# Bind the summary table and the total row
missing_data_summary <- rbind(missing_data_summary, total_row)



# Convert to a gtsummary table
missing_data_summary %>%
  gt() %>%
  tab_header(
    title = "Missing Data Summary for Smoking Sessation"
  ) %>%
  cols_label(
    Variables = "Variables",
    `Missing Data` = "Missing Values",
    Percent_Missing = "Percentage Missing (%)"
  ) %>%
  fmt_number(
    columns = vars(Percent_Missing),
    decimals = 2  # Format percentage to two decimal places
  )


```




```{r}
 #Define Treatment Groups
project2 <- project2 %>%
  mutate(treatment_groups = case_when(
    Var == 1 & BA == 1 ~ "BA_VA",
    Var == 0 & BA == 0 ~ "ST_Placebo",
    Var == 0 & BA == 1 ~ "BA_Placebo",
    Var == 1 & BA == 0 ~ "ST_VA"
  ))

# Create demographic/ baseline characeteristcs tabl

demographics_table <- project2 %>%
  group_by(treatment_groups) %>%
  summarise(
     N= n(),
    `Mean Ages` = round(mean(age_ps, na.rm = TRUE), 1),
    `Standard Deviation Ages` = round(sd(age_ps, na.rm = TRUE), 1),
     Sex = round(sum(as.numeric(as.character(sex_ps)), na.rm = TRUE), 1),
    Blacks = round(sum(as.numeric(as.character(Black)), na.rm = TRUE), 1),
    Hispanics = round(sum(as.numeric(as.character(Hisp)), na.rm = TRUE), 1),
    `Non-Hispanic Whites` = round(sum(as.numeric(as.character(NHW)), na.rm = TRUE), 1),
    `Black Percentage` = round(mean(as.numeric(as.character(Black)), na.rm = TRUE) * 100, 1),
    `Hispanic Percentage` = round(mean(as.numeric(as.character(Hisp)), na.rm = TRUE) * 100, 1),
    `Non-Hispanic White Percentage` = round(mean(as.numeric(as.character(NHW)), na.rm = TRUE) * 100, 1),
    `Education Levels`= c(""),
   `Income Levels`= c("") , 
   `Major Depressive Disorder`= c(""),
    `Antidepressant Medication (%)`=round(mean(as.numeric(as.character(antidepmed)), na.rm = TRUE)*100, 1),
    `Other Lifetime Diagnosis`= round(sum(as.numeric(as.character(otherdiag)), na.rm = TRUE), 1),
    `Cigarette Type`= c(""),
   ` Menthol Only` = round(sum(as.numeric(as.character(Only.Menthol)), na.rm = TRUE), 1),
   `Smoking`= c(""),
   `Cigarettes Per Day at Baseline` = round(mean(as.numeric(as.character(cpd_ps)), na.rm = TRUE), 1),
   `Cigarette Reward Value at Baseline`=round(mean(as.numeric(as.character(crv_total_pq1)), na.rm = TRUE), 1),
    `FTCD at Baseline`=round(mean(as.numeric(as.character(ftcd_score)), na.rm = TRUE), 2),
  `Readiness to Quit`=round(mean(as.numeric(as.character(readiness)), na.rm = TRUE), 1),
  `Time to smoking upon waking up`= c(""),
  `Smoking 5 minutes into waking up (%)`=round(mean(as.numeric(as.character(ftcd.5.mins)), na.rm = TRUE)*100, 1),
  
  `Pleasurable Events at Baseline`= c(""),
  `Substitute Reinforcers`= round(mean(as.numeric(hedonsum_n_pq1), na.rm = TRUE), 1),
  `Complimentary Reinforcers`= round(mean(as.numeric(hedonsum_y_pq1), na.rm = TRUE), 1)
    
  )

education_counts <- project2 %>%
  group_by(treatment_groups, edu) %>%
  summarize(Education_Count = n()) %>%
  pivot_wider(names_from = edu, values_from = Education_Count, values_fill = 0)



inc_counts <- project2 %>%
  group_by(treatment_groups, inc) %>%
  summarize(Income_Count = n()) %>%
  pivot_wider(names_from = inc, values_from = Income_Count, values_fill = 0)



mdd_counts <- project2 %>%
  group_by(treatment_groups, mde_curr) %>%
  summarize(MDE_Count = n()) %>%
  pivot_wider(names_from = mde_curr, values_from = MDE_Count, values_fill = 0)

sex_counts <- project2 %>%
  group_by(treatment_groups, sex_ps) %>%
  summarize(Sex_Count = n()) %>%
  pivot_wider(names_from = sex_ps, values_from = Sex_Count, values_fill = 0)



demographics_table <- demographics_table %>%
  left_join(education_counts, by = "treatment_groups") %>%
  left_join(inc_counts, by = "treatment_groups") %>%
  left_join(mdd_counts, by = "treatment_groups")

demographics_table <- demographics_table %>%
  select(treatment_groups, `N`, `Mean Ages`, `Standard Deviation Ages`, `Sex`,Blacks, Hispanics, `Black Percentage`, `Hispanic Percentage`,`Non-Hispanic Whites`,`Non-Hispanic White Percentage`,`Education Levels`, `1.x`,`2.x`,`3.x`,`4.x`,`5.x`, `Income Levels`, `1.y`,`2.y`,`3.y`,`4.y`,`5.y`,`NA`, `Major Depressive Disorder`, `0`,`1`,
         `Cigarette Type`, ` Menthol Only`,  everything())


  

# Transpose the table
transposed_table <- as.data.frame(t(demographics_table))

# Update column names to reflect the new format
colnames(transposed_table) <- transposed_table[1, ]  # Set the first row as column names
transposed_table <- transposed_table[-1, ]           # Remove the first row (now redundant)
#rownames(transposed_table) <- c("Blacks")            # Rename rows if needed



#Create Kable Extra Table 
#Create Kable Extra Table 
kable(transposed_table, 
      caption = "Demographics Table of the Smoking Cessation Participants",
      col.names = c("Demograhic Characteristics Variable", "BA+Placebo", "BA+VA", "ST+Placebo", "ST+VA"),
      digits =2) # Set digits for p-values and chi-square



```




```{r, fig.height=6, fig.width=10}


# Compute the correlation matrix using complete observations
cor_matrix <- cor(project2, use = "complete.obs")  # Use complete.obs to ignore NAs

# Melt the correlation matrix for ggplot2
cor_data <- melt(cor_matrix)


#Cessation Smoking correlation plot 
cessation_smoking_plot<-ggplot(data = cor_data, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = "white") +
  geom_text(aes(label = round(value, 2)), color = "black", size = 4) +
  scale_fill_gradient2(low = "hotpink", high = "royalblue", mid = "white",
                       midpoint = 0, limit = c(-1, 1), space = "Lab",
                       name = "Correlation") +
  labs(title = "Correlation of Smoking Cessation",
       x= "Variables",
       y= "Variables") +
  theme_minimal(base_family = "Times") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        legend.position = "bottom",
        plot.title = element_text(hjust = 0.5, size= 20))

cessation_smoking_plot
  



```


```{r}
 #Define Treatment Groups
project2 <- project2 %>%
  mutate(treatment_groups = case_when(
    Var == 1 & BA == 1 ~ "BA_VA",
    Var == 0 & BA == 0 ~ "ST_Placebo",
    Var == 0 & BA == 1 ~ "BA_Placebo",
    Var == 1 & BA == 0 ~ "ST_VA"
  ))
#Change variables into factor and continous variables 
factor_vars <- c("abst","Var","BA","sex_ps", "NHW",
                 "Black", "Hisp", "inc", "edu","ftcd_score",
                 "ftcd.5.mins", "otherdiag", "antidepmed","mde_curr",
                 "Only.Menthol","readiness", "treatment_groups")

#Mutate variables as factors
project2<- project2%>%
  mutate(across(all_of(factor_vars), as.factor))


chi_square_results <- data.frame(
  Variable1 = character(),
  Variable2 = character(),
  Chi_Square = numeric(),
  Degrees_of_Freedom = numeric(),
  P_Value = numeric(),
  stringsAsFactors = FALSE
)

# Loop through each unique pair of variables
for (i in 1:(length(factor_vars) - 1)) {
  for (j in (i + 1):length(factor_vars)) {
    var1 <- factor_vars[i]
    var2 <- factor_vars[j]
    
    # Check if both columns exist in the data frame
    if (all(c(var1, var2) %in% colnames(project2))) {
      # Create a contingency table
      table_data <- table(project2[[var1]], project2[[var2]])
      
      # Perform the chi-square test
      chi_test <- chisq.test(table_data)
      
       # Add results to the data frame
      chi_square_results <- rbind(chi_square_results, data.frame(
        Variable1 = var1,
        Variable2 = var2,
        Chi_Square = chi_test$statistic,
        Degrees_of_Freedom = chi_test$parameter,
        P_Value = chi_test$p.value
      ))
    }
  }
}


significance_level <- 0.05

# Filter for significant associations only
significant_results <- chi_square_results %>%
  filter(P_Value < significance_level)

dim(significant_results)
# Display the significant results as a kable table
kable(significant_results, 
      caption = "Significant Chi-Square Test Results", 
      col.names = c("Variable 1", "Variable 2", "Chi-Square", "Degrees of Freedom", "P-Value"),
      digits = 4) # Set digits for p-values and chi-square

mean(significant_results$Chi_Square)
```






```{r}
# Find the variables in project2 that are not in factor_vars
continous_vars <- setdiff(names(project2), factor_vars)

project2 <- project2 %>%
  mutate(across(all_of(continous_vars), as.numeric))

# Select only numeric columns for the correlation plot
numeric_data <- project2 %>% select(all_of(continous_vars))

# Calculate the correlation matrix
cor_matrix <- cor(numeric_data, use = "complete.obs")


# Melt the correlation matrix for ggplot2
cor_data2 <- melt(cor_matrix)


#Cessation Smoking correlation plot 
cessation_smoking_plot2<-ggplot(data = cor_data2, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = "white") +
  geom_text(aes(label = round(value, 2)), color = "black", size = 4) +
  scale_fill_gradient2(low = "hotpink", high = "royalblue", mid = "white",
                       midpoint = 0, limit = c(-1, 1), space = "Lab",
                       name = "Correlation") +
  labs(title = "Correlation of Smoking Cessation",
       x= "Variables",
       y= "Variables") +
  theme_minimal(base_family = "Times") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        legend.position = "bottom",
        plot.title = element_text(hjust = 0.5, size= 20))

cessation_smoking_plot2
  


```


# Logistic Modeling

```{r, message=FALSE, warning=FALSE}

library(mice)
library(caret)
library(dplyr)
library(broom)  # For tidying model outputs
library(pROC)   # For ROC and AUC calculations

# Data Imputation for Logistic Modeling
imputed_data1 <- mice(project2, m = 5, method = 'pmm', maxit = 10, seed = 222)

# Initialize lists to store model results, significant coefficients, and AUC values
model_results <- list()
model_results2 <- list()
significant_coef_estimates <- list()
significant_coef_estimates2 <- list()
significant_coef_estimates3 <- list()
significant_coef_estimates4 <- list()
auc_train_main <- list()
auc_test_main <- list()
auc_train_interaction <- list()
auc_test_interaction <- list()

# Loop over each imputed dataset
for (i in 1:5) {
  # Get a complete dataset from the imputed data
  complete_data_ <- complete(imputed_data1, i)
  
  # Split into training and testing sets
  set.seed(222)
  trainIndex1 <- createDataPartition(complete_data_$abst, p = 0.7, list = FALSE)
  train_data1 <- complete_data_[trainIndex1, ]
  test_data1 <- complete_data_[-trainIndex1, ]
  
  # Fit the logistic model on Training and Test Data
  main_effects <- glm(abst ~ ., family = binomial(link = "logit"), data = train_data1)
  main_effects2 <- glm(abst ~ ., family = binomial(link = "logit"), data = test_data1)
  
  # Fit the logistic model with interaction terms on Training Data
  interaction_effects <- glm(abst ~ Var + BA + age_ps + sex_ps + NHW + Black + Hisp +
                             inc + edu + ftcd_score + ftcd.5.mins + bdi_score_w00 + cpd_ps +
                             crv_total_pq1 + hedonsum_n_pq1 + hedonsum_y_pq1 + shaps_score_pq1 +
                             otherdiag + antidepmed + mde_curr + NMR + Only.Menthol + readiness +
                             sex_ps * Black + sex_ps * NHW + sex_ps * readiness +
                             NHW * inc + NHW * edu + NHW * antidepmed +
                             NHW * Only.Menthol + NHW * readiness + Black * inc +
                             Black * edu + Black * Only.Menthol + Black * readiness +
                             Hisp * Only.Menthol, family = binomial(link = "logit"), data = train_data1)
  
  # Fit the logistic model with interaction terms on Test Data
  interaction_effects2 <- glm(abst ~ Var + BA + age_ps + sex_ps + NHW + Black + Hisp +
                              inc + edu + ftcd_score + ftcd.5.mins + bdi_score_w00 + cpd_ps +
                              crv_total_pq1 + hedonsum_n_pq1 + hedonsum_y_pq1 + shaps_score_pq1 +
                              otherdiag + antidepmed + mde_curr + NMR + Only.Menthol + readiness +
                              sex_ps * Black + sex_ps * NHW + sex_ps * readiness +
                              NHW * inc + NHW * edu + NHW * antidepmed +
                              NHW * Only.Menthol + NHW * readiness + Black * inc +
                              Black * edu + Black * Only.Menthol + Black * readiness +
                              Hisp * Only.Menthol, family = binomial(link = "logit"), data = test_data1)
  
  
  
  # Fit the logistic model on Training and Test Data
  main_effects <- glm(abst ~ ., family = binomial(link = "logit"), data = train_data1)
  main_effects2<- glm(abst ~ ., family = binomial(link = "logit"), data = test_data1)
  
  
  # Tidy the model summary and add an identifier column for the imputed dataset
  model_summary <- broom::tidy(main_effects) %>%
    mutate(imputation = i)
  
    model_summary2 <- broom::tidy(main_effects2) %>%
    mutate(imputation = i)
  
  # Store the tidy data frame
  model_results[[i]] <- model_summary
  model_results2[[i]] <- model_summary2

    
  # Store only statistically significant coefficients (p-value < 0.05)
  significant_coef_estimates[[i]] <- broom::tidy(main_effects) %>%
    filter(p.value < 0.05) %>%
    select(term, estimate) %>%
    mutate(imputation = i)
  
  
  # Store only statistically significant coefficients (p-value < 0.05)
  significant_coef_estimates2[[i]] <- broom::tidy(main_effects2) %>%
    filter(p.value < 0.05) %>%
    select(term, estimate) %>%
    mutate(imputation = i)
  
  
  # Store only statistically significant coefficients (p-value < 0.05)
  significant_coef_estimates3[[i]] <- broom::tidy(interaction_effects) %>%
    filter(p.value < 0.05) %>%
    select(term, estimate) %>%
    mutate(imputation = i)
  
   # Store only statistically significant coefficients (p-value < 0.05) Test Data
  significant_coef_estimates4[[i]] <- broom::tidy(interaction_effects2) %>%
    filter(p.value < 0.05) %>%
    select(term, estimate) %>%
    mutate(imputation = i)
  
  # ROC Curve and AUC calculation for Main Effects Model
  train_data1$predicted_probs_main_train <- predict(main_effects, newdata = train_data1, type = "response")
  test_data1$predicted_probs_main_test <- predict(main_effects2, newdata = test_data1, type = "response")
  roc_train_main <- roc(train_data1$abst, train_data1$predicted_probs_main_train)
  roc_test_main <- roc(test_data1$abst, test_data1$predicted_probs_main_test)
  
  # ROC Curve and AUC calculation for Interaction Model
  train_data1$predicted_probs_interaction_train <- predict(interaction_effects, newdata = train_data1, type = "response")
  test_data1$predicted_probs_interaction_test <- predict(interaction_effects2, newdata = test_data1, type = "response")
  roc_train_interaction <- roc(train_data1$abst, train_data1$predicted_probs_interaction_train)
  roc_test_interaction <- roc(test_data1$abst, test_data1$predicted_probs_interaction_test)
  
  
  # # Calculate AUC values for legend
  auc_train_main_val <- auc(roc_train_main)
  auc_test_main_val <- auc(roc_test_main)
  auc_train_interaction_val <- auc(roc_train_interaction)
  auc_test_interaction_val <- auc(roc_test_interaction)
  
  # Plot ROC curves for main and interaction effects on the same plot
  plot(roc_train_main, col = "blue", lty = 1, main = paste("ROC Curves (Imputation", i, ")"))
  lines(roc_test_main, col = "red", lty = 1)
  lines(roc_train_interaction, col = "blue", lty = 2)
  lines(roc_test_interaction, col = "red", lty = 2)
  
  # Add a legend with AUC values
  legend("bottomright", 
         legend = c(paste("Training (Main Effects), AUC =", round(auc_train_main_val, 3)),
                    paste("Test (Main Effects), AUC =", round(auc_test_main_val, 3)),
                    paste("Training (Interaction Effects), AUC =", round(auc_train_interaction_val, 3)),
                    paste("Test (Interaction Effects), AUC =", round(auc_test_interaction_val, 3))),
         col = c("blue", "red", "blue", "red"), 
         lty = c(1, 1, 2, 2), 
         lwd = 2)
}
```


## Logistic Regression Significant Predictor Variables for Training Data
```{r}
# Combine all data frames into a single data frame
combined_results <- bind_rows(model_results)

# View the combined results
#combined_results

# Filter only the significant coefficients (p-value < 0.05)
significant_logistic_results <- combined_results %>%
  filter(p.value < 0.05)

# Display results in a kable table
significant_res <- kable(significant_logistic_results, 
                                  caption = "Logistic Model Results (Statistically Significant Coefficients Across Imputations)") %>%
  kable_styling(full_width = F, font_size = 12)

significant_res


```





## Pooled Results from Logistic Regression Model on Training Data
```{r}

# Combine all significant coefficients into a single data frame
combined_significant_results <- bind_rows(significant_coef_estimates)

# Calculate pooled estimates only for terms that are consistently significant across imputations
pooled_significant_results <- combined_significant_results %>%
  group_by(term) %>%
  summarize(
    Mean = mean(estimate, na.rm = TRUE),
    SE_within = sqrt(mean((estimate - mean(estimate, na.rm = TRUE))^2, na.rm = TRUE)),
    SE_between = var(estimate, na.rm = TRUE),
    Count = n(),  # Count of imputations where the term was significant
    .groups = 'drop'
  ) %>%
  filter(Count == 5) %>%  # Only keep terms significant in all imputations
  mutate(
    Pooled_SE = sqrt(SE_within + (1 + 1/5) * SE_between),  # Rubin's Rules for SE
    Lower_CI = Mean - 1.96 * Pooled_SE,
    Upper_CI = Mean + 1.96 * Pooled_SE
  )

# Display results in a kable table
kable_pooled_significant <- kable(pooled_significant_results, 
                                  caption = "Pooled Logistic Model Results (Statistically Significant Coefficients Across Imputations)") %>%
  kable_styling(full_width = F, font_size = 12)

kable_pooled_significant




```


# Logistic with Testing Data 
```{r}



# Combine all significant coefficients into a single data frame
combined_significant_results2 <- bind_rows(significant_coef_estimates2)

# Calculate pooled estimates only for terms that are consistently significant across imputations
pooled_significant_results2 <- combined_significant_results2 %>%
  group_by(term) %>%
  summarize(
    Mean = mean(estimate, na.rm = TRUE),
    SE_within = sqrt(mean((estimate - mean(estimate, na.rm = TRUE))^2, na.rm = TRUE)),
    SE_between = var(estimate, na.rm = TRUE),
    Count = n(),  # Count of imputations where the term was significant
    .groups = 'drop'
  ) %>%
  filter(Count == 5) %>%  # Only keep terms significant in all imputations
  mutate(
    Pooled_SE = sqrt(SE_within + (1 + 1/5) * SE_between),  # Rubin's Rules for SE
    Lower_CI = Mean - 1.96 * Pooled_SE,
    Upper_CI = Mean + 1.96 * Pooled_SE
  )

# Display results in a kable table
kable_pooled_significant2 <- kable(pooled_significant_results2, 
                                  caption = "Pooled Logistic Model Results with Test Data Main Effects (Statistically Significant Coefficients Across Imputations)") %>%
  kable_styling(full_width = F, font_size = 12)

kable_pooled_significant2







```

## Logistic Regression Using Training Data and Interactions
```{r}
# Combine all significant coefficients into a single data frame
combined_significant_results3 <- bind_rows(significant_coef_estimates3)

# Calculate pooled estimates only for terms that are consistently significant across imputations
pooled_significant_results3 <- combined_significant_results3 %>%
  group_by(term) %>%
  summarize(
    Mean = mean(estimate, na.rm = TRUE),
    SE_within = sqrt(mean((estimate - mean(estimate, na.rm = TRUE))^2, na.rm = TRUE)),
    SE_between = var(estimate, na.rm = TRUE),
    Count = n(),  # Count of imputations where the term was significant
    .groups = 'drop'
  ) %>%
  filter(Count == 5) %>%  # Only keep terms significant in all imputations
  mutate(
    Pooled_SE = sqrt(SE_within + (1 + 1/5) * SE_between),  # Rubin's Rules for SE
    Lower_CI = Mean - 1.96 * Pooled_SE,
    Upper_CI = Mean + 1.96 * Pooled_SE
  )

# Display results in a kable table
kable_pooled_significant3 <- kable(pooled_significant_results3, 
                                  caption = "Pooled Logistic Model Results on Training Data (Statistically Significant Coefficients Across Imputations)") %>%
  kable_styling(full_width = F, font_size = 12)

kable_pooled_significant3

```

## Logistic Regression Using Test Data and Interactions
```{r}
# Combine all significant coefficients into a single data frame
combined_significant_results4 <- bind_rows(significant_coef_estimates4)

# Calculate pooled estimates only for terms that are consistently significant across imputations
pooled_significant_results4<- combined_significant_results4 %>%
  group_by(term) %>%
  summarize(
    Mean = mean(estimate, na.rm = TRUE),
    SE_within = sqrt(mean((estimate - mean(estimate, na.rm = TRUE))^2, na.rm = TRUE)),
    SE_between = var(estimate, na.rm = TRUE),
    Count = n(),  # Count of imputations where the term was significant
    .groups = 'drop'
  ) %>%
  filter(Count == 5) %>%  # Only keep terms significant in all imputations
  mutate(
    Pooled_SE = sqrt(SE_within + (1 + 1/5) * SE_between),  # Rubin's Rules for SE
    Lower_CI = Mean - 1.96 * Pooled_SE,
    Upper_CI = Mean + 1.96 * Pooled_SE
  )

# Display results in a kable table
kable_pooled_significant4 <- kable(pooled_significant_results4, 
                                  caption = "Pooled Logistic Model Results on Test Data (Statistically Significant Coefficients Across Imputations)") %>%
  kable_styling(full_width = F, font_size = 12)

kable_pooled_significant4

```
































```{r}

# Create a data frame to store pooled results for Lasso
logistic_pooled_results <- data.frame(Variable = rownames(logistic_coef_estimates[[1]]), 
                                   Mean = NA, SE = NA)

# Calculate the mean and standard error for each coefficient
for (var in logisic_pooled_results$Variable) {
  coefs <- sapply(lasso_coef_estimates, function(x) as.numeric(x[var, 1]))
  
  lasso_pooled_results[lasso_pooled_results$Variable == var, "Mean"] <- mean(coefs, na.rm = TRUE)
  
  # Rubin's Rules for standard error calculation
  se_within <- sqrt(mean((coefs - mean(coefs))^2))
  se_between <- var(coefs, na.rm = TRUE)
  pooled_se <- sqrt(se_within + (1 + 1/m) * se_between)
  
  lasso_pooled_results[lasso_pooled_results$Variable == var, "SE"] <- pooled_se
}

# Filter for non-zero mean coefficients
lasso_selected_vars <- lasso_pooled_results[lasso_pooled_results$Mean != 0 & 
                                              lasso_pooled_results$Variable != "(Intercept)", ]
lasso_selected_sorted <- lasso_selected_vars[order(-lasso_selected_vars$Mean), ]

# Create a table using kable for Lasso results
library(knitr)
library(kableExtra)
kable_lasso <- kable(lasso_selected_sorted, caption = "Lasso Model Selected Variables (Non-Zero Coefficients)") %>%
  kable_styling(full_width = F, font_size = 12)

kable_lasso








```








```{r}
#Logistic with Interactions 


# Data Imputation for Logistic Modeling
imputed_data <- mice(project2, m = 5, method = 'pmm', maxit = 10, seed = 222)

# Initialize a list to store significant coefficient estimates from each imputation
significant_coef_estimates2 <- list()
significant_coef_estimates3 <- list()
# Loop over each imputed dataset to fit the logistic model and extract significant coefficients
for (i in 1:5) {
  # Get a complete dataset from the imputed data
  complete_data <- complete(imputed_data, i)
  
  # Split into training and testing sets
  set.seed(222)
  trainIndex <- createDataPartition(complete_data$abst, p = 0.7, list = FALSE)
  train_data <- complete_data[trainIndex, ]
  test_data<- complete_data[-trainIndex,]
  
 

  # Fit the logistic model
 interaction_effects <- glm(abst ~ Var+ BA + age_ps + sex_ps + NHW +Black + Hisp+
                            inc + edu+ ftcd_score+ ftcd.5.mins + bdi_score_w00+ cpd_ps+
                            crv_total_pq1 + hedonsum_n_pq1+ hedonsum_y_pq1 +shaps_score_pq1+
                            otherdiag+ antidepmed +mde_curr +NMR +  Only.Menthol+ readiness
                            + sex_ps * Black +sex_ps * NHW + sex_ps * readiness +
                            NHW * inc+  NHW * edu+  NHW *antidepmed +
                            NHW* Only.Menthol+ NHW * readiness + Black * inc 
                           + Black*edu + Black* Only.Menthol + Black*readiness + Hisp*Only.Menthol,
                           family = binomial(link = "logit"), data = train_data)

interaction_effects2 <- glm(abst ~ Var+ BA + age_ps + sex_ps + NHW +Black + Hisp+
                            inc + edu+ ftcd_score+ ftcd.5.mins + bdi_score_w00+ cpd_ps+
                            crv_total_pq1 + hedonsum_n_pq1+ hedonsum_y_pq1 +shaps_score_pq1+
                            otherdiag+ antidepmed +mde_curr +NMR +  Only.Menthol+ readiness
                            + sex_ps * Black +sex_ps * NHW + sex_ps * readiness +
                            NHW * inc+  NHW * edu+  NHW *antidepmed +
                            NHW* Only.Menthol+ NHW * readiness + Black * inc 
                           + Black*edu + Black* Only.Menthol + Black*readiness + Hisp*Only.Menthol,
                           family = binomial(link = "logit"), data = test_data)

 
 
 
 

  # Store only statistically significant coefficients (p-value < 0.05) Training Data
  significant_coef_estimates2[[i]] <- broom::tidy(interaction_effects) %>%
    filter(p.value < 0.05) %>%
    select(term, estimate) %>%
    mutate(imputation = i)
  
  
  # Store only statistically significant coefficients (p-value < 0.05) Test Data
  significant_coef_estimates3[[i]] <- broom::tidy(interaction_effects2) %>%
    filter(p.value < 0.05) %>%
    select(term, estimate) %>%
    mutate(imputation = i)
  
  
  
  
  
}

# Combine all significant coefficients into a single data frame
combined_significant_results2 <- bind_rows(significant_coef_estimates2)

# Calculate pooled estimates only for terms that are consistently significant across imputations
pooled_significant_results2 <- combined_significant_results2 %>%
  group_by(term) %>%
  summarize(
    Mean = mean(estimate, na.rm = TRUE),
    SE_within = sqrt(mean((estimate - mean(estimate, na.rm = TRUE))^2, na.rm = TRUE)),
    SE_between = var(estimate, na.rm = TRUE),
    Count = n(),  # Count of imputations where the term was significant
    .groups = 'drop'
  ) %>%
  filter(Count == 5) %>%  # Only keep terms significant in all imputations
  mutate(
    Pooled_SE = sqrt(SE_within + (1 + 1/5) * SE_between),  # Rubin's Rules for SE
    Lower_CI = Mean - 1.96 * Pooled_SE,
    Upper_CI = Mean + 1.96 * Pooled_SE
  )

# Display results in a kable table
kable_pooled_significant2 <- kable(pooled_significant_results2, 
                                  caption = "Pooled Logistic Model Results with Interactions  (Statistically Significant Coefficients Across Imputations)") %>%
  kable_styling(full_width = F, font_size = 12)

kable_pooled_significant2












```



```{r}
# Combine all significant coefficients into a single data frame
combined_significant_results3 <- bind_rows(significant_coef_estimates3)

# Calculate pooled estimates only for terms that are consistently significant across imputations
pooled_significant_results3 <- combined_significant_results3 %>%
  group_by(term) %>%
  summarize(
    Mean = mean(estimate, na.rm = TRUE),
    SE_within = sqrt(mean((estimate - mean(estimate, na.rm = TRUE))^2, na.rm = TRUE)),
    SE_between = var(estimate, na.rm = TRUE),
    Count = n(),  # Count of imputations where the term was significant
    .groups = 'drop'
  ) %>%
  filter(Count == 5) %>%  # Only keep terms significant in all imputations
  mutate(
    Pooled_SE = sqrt(SE_within + (1 + 1/5) * SE_between),  # Rubin's Rules for SE
    Lower_CI = Mean - 1.96 * Pooled_SE,
    Upper_CI = Mean + 1.96 * Pooled_SE
  )

# Display results in a kable table
kable_pooled_significant3 <- kable(pooled_significant_results3 ,
                                  caption = "Pooled Logistic Model Results with Interactions on Test Data (Statistically Significant Coefficients Across Imputations)") %>%
  kable_styling(full_width = F, font_size = 12)

kable_pooled_significant3




```












```{r}

library(mice)
library(caret)
library(glmnet)
library(knitr)
library(kableExtra)
library(pROC)
library(ggplot2)
library(gridExtra)

# Define the formula for Lasso
formula <- abst ~ .  # This includes all variables in the dataset for prediction

# Set up parameters
set.seed(1)
m <- 5
lasso_coef_estimates <- list()
lasso_optimal_lambdas <- list()
lasso_train_predictions <- list()
lasso_test_predictions <- list()
roc_list <- list()  # To store ROC plots


# Impute missing data
imputed_data1 <- mice(project2, m = m, method = 'pmm', maxit = 10, seed = 222)

# Set up train-test split (80% train, 20% test) using the first imputed dataset
trainIndex <- createDataPartition(complete(imputed_data1, 1)$abst, p = 0.7, list = FALSE)

# Loop over each imputed dataset
for (i in 1:m) {
  completed_data <- complete(imputed_data1, i)
  
  # Split data
  train_data <- completed_data[trainIndex, ]
  test_data <- completed_data[-trainIndex, ]
  
  # Model matrix for training and test sets
  X_train <- model.matrix(formula, data = train_data)[, -1]  # Remove intercept column
  Y_train <- train_data$abst
  X_test <- model.matrix(formula, data = test_data)[, -1]  # Remove intercept column
  Y_test <- test_data$abst
  
  # Fit Lasso model with cross-validation on training data
  cv_fit <- cv.glmnet(X_train, Y_train, alpha = 1, family = "binomial")
  
  # Store coefficients
  lasso_coef_estimates[[i]] <- coef(cv_fit, s = "lambda.min")
  
  # Store optimal lambda for reference
  lasso_optimal_lambdas[[i]] <- cv_fit$lambda.min
  
  # Predict on both train and test sets using the optimal lambda
  lasso_train_predictions[[i]] <- predict(cv_fit, newx = X_train, s = "lambda.min", type = "response")
  lasso_test_predictions[[i]] <- predict(cv_fit, newx = X_test, s = "lambda.min", type = "response")
  
  # Calculate ROC and AUC for training and test data
  roc_train <- roc(Y_train, as.numeric(lasso_train_predictions[[i]]))
  auc_train <- auc(roc_train)
  
  roc_test <- roc(Y_test, as.numeric(lasso_test_predictions[[i]]))
  auc_test <- auc(roc_test)
  
 # Create ROC plot for both training and test data
  p <- ggplot() +
    geom_line(aes(x = roc_train$specificities, y = roc_train$sensitivities), color = "blue") +
    geom_line(aes(x = roc_test$specificities, y = roc_test$sensitivities), color = "red") +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "gray") +  # Add diagonal reference line
    labs(title = paste("ROC Curves for Imputation", i),
         x = "1 - Specificity",
         y = "Sensitivity") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5, size = 10)) +  # Smaller title size
    scale_x_reverse() +
    # Add AUC to the legend
    annotate("text", x = 0.3, y = 0.2, label = paste(
      "Train AUC =", round(auc_train, 3), "\nTest AUC =", round(auc_test, 3)), 
      color = "black", size = 3, hjust = 0)
 
  # Add plot to list
  roc_list[[i]] <- p
}

# Arrange all ROC plots in a grid layout
grid.arrange(grobs = roc_list, ncol = 2)

# Create a data frame to store pooled results for Lasso
lasso_pooled_results <- data.frame(Variable = rownames(lasso_coef_estimates[[1]]), 
                                   Mean = NA, SE = NA)

# Calculate the mean and standard error for each coefficient
for (var in lasso_pooled_results$Variable) {
  coefs <- sapply(lasso_coef_estimates, function(x) as.numeric(x[var, 1]))
  
  # Mean of the coefficients across imputations
  lasso_pooled_results[lasso_pooled_results$Variable == var, "Mean"] <- mean(coefs, na.rm = TRUE)
  
  # Rubin's Rules for standard error calculation
  se_within <- sqrt(mean((coefs - mean(coefs, na.rm = TRUE))^2))
  se_between <- var(coefs, na.rm = TRUE)
  pooled_se <- sqrt(se_within + (1 + 1/m) * se_between)
  
  lasso_pooled_results[lasso_pooled_results$Variable == var, "SE"] <- pooled_se
}

# Filter for non-zero mean coefficients
lasso_selected_vars <- lasso_pooled_results[lasso_pooled_results$Mean != 0 & 
                                              lasso_pooled_results$Variable != "(Intercept)", ]
lasso_selected_sorted <- lasso_selected_vars[order(-abs(lasso_selected_vars$Mean)), ]

# Create a table using kable for Lasso results
kable_lasso_model_table<- kable(lasso_selected_sorted, caption = "Lasso Model Selected Variables (Non-Zero Coefficients)") %>%
  kable_styling(full_width = F, font_size = 12)

kable_lasso_model_table





```

#```{r}


#predicted_probs_test <- as.numeric(lasso_test_predictions[[1]])
# Define a function to plot calibration
#plot_calibration <- function(predicted_probs, actual_outcomes) {
  # Create bins for predicted probabilities
 # calibration_data <- data.frame(
  #  predicted = predicted_probs,
   # observed = actual_outcomes
  #)
  
  # Group data into bins (e.g., deciles) and calculate mean predicted and observed values
  #calibration_data$bin <- cut(calibration_data$predicted, breaks = seq(0, 1, by = 0.1), #include.lowest = TRUE)
  
 # calibration_summary <- calibration_data %>%
  #  group_by(bin) %>%
   # summarise(
   #   mean_predicted = mean(predicted),
    #  mean_observed = mean(observed)
   # )
  
  # Create the calibration plot
  #ggplot(calibration_summary, aes(x = mean_predicted, y = mean_observed)) +
    #geom_point(size = 3, color = "blue") +
   # geom_line(aes(y = mean_predicted), linetype = "dashed", color = "gray") +
    #labs(
     # title = "Calibration Plot",
      #x = "Mean Predicted Probability",
      #y = "Mean Observed Probability"
   # ) +
    #theme_minimal()
#}

# Run calibration plot for the first imputed dataset (example)
# Using test data predictions from the first imputation (adjust accordingly)
#predicted_probs_test <- as.numeric(lasso_test_predictions[[1]])
#actual_outcomes_test <- Y_test

# Plot calibration
#plot_calibration(predicted_probs_test, actual_outcomes_test)
#```




```{r}
# Predict on test set using the optimal lambda and store predictions
lasso_test_predictions[[i]] <- predict(cv_fit, newx = X_test, s = "lambda.min", type = "response")

# Check if the predictions were stored
print(lasso_test_predictions[[i]])



```


















